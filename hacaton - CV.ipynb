{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Идеи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Необходимо классифицировать изображения на 12 классов. Используем простую сверточную сеть с двумя полносвязными слоями. На выходе - слой размера 12 с softmax. На входе - тензор батча изобржаний\n",
    "2. Изображения очень похожи друг на друга. В центре - побег растения, фон - почва (камни, замля и т.д.)\n",
    "3. Изображения не стандартного формата (вроде). Необходимо привести к одному масштабу. \n",
    "4. Так как фото сделаны сверху - нет строгой ориентации побега (однако, он центрирован) и нет строгого отношения размер изображения/размер побега. Поэтому точно классной идеей будет применить аугментацию изображений поворотом и масштабированием. Возможно, также сдвигом. ImageDataGenerator\n",
    "5. В качестве доп. фичей можно применить гистограмму цветов в области побега\n",
    "6. Обучить несколько независимых сетей на частях данных (допустим, 4), делать стекинг на тестовой выборке из их предсказаний. Сам стекинг не обучать (для скорости)\n",
    "7. Попробовать дообучать несколько слоев ResNet (хотя, эта сеть обучена для слишком большого количества изображений)\n",
    "8. После обучения смотреть матрицу ошибок, выделять дополнительно то, что можно дообучить в случае больших ошибок сети\n",
    "9. Подумать над размером и стратификацией батча (видел батчи по 16-20 фото, но у нас 12 классов. Так, есть большая вероятность не попадания нескольких классов в батч)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import imageio\n",
    "\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Maximum\n",
    "from keras.layers import ZeroPadding2D\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras import regularizers\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.transform import resize as imresize\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# from subprocess import check_output\n",
    "# print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# global vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "EPOCHS = 30\n",
    "RANDOM_STATE = 11\n",
    "CLASS = {\n",
    "    'Black-grass': 0,\n",
    "    'Charlock': 1,\n",
    "    'Cleavers': 2,\n",
    "    'Common Chickweed': 3,\n",
    "    'Common wheat': 4,\n",
    "    'Fat Hen': 5,\n",
    "    'Loose Silky-bent': 6,\n",
    "    'Maize': 7,\n",
    "    'Scentless Mayweed': 8,\n",
    "    'Shepherds Purse': 9,\n",
    "    'Small-flowered Cranesbill': 10,\n",
    "    'Sugar beet': 11\n",
    "}\n",
    "\n",
    "INV_CLASS = {\n",
    "    0: 'Black-grass',\n",
    "    1: 'Charlock',\n",
    "    2: 'Cleavers',\n",
    "    3: 'Common Chickweed',\n",
    "    4: 'Common wheat',\n",
    "    5: 'Fat Hen',\n",
    "    6: 'Loose Silky-bent',\n",
    "    7: 'Maize',\n",
    "    8: 'Scentless Mayweed',\n",
    "    9: 'Shepherds Purse',\n",
    "    10: 'Small-flowered Cranesbill',\n",
    "    11: 'Sugar beet'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = ImageDataGenerator(\n",
    "            rotation_range=360.,\n",
    "            width_shift_range=0.3,\n",
    "            height_shift_range=0.3,\n",
    "            zoom_range=0.3,\n",
    "            horizontal_flip=True,\n",
    "            vertical_flip=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras_preprocessing.image.ImageDataGenerator at 0xbbe8208>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Создание сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_set(inp_layer, n, activation, drop_rate=0.):\n",
    "    dp = Dropout(drop_rate)(inp_layer)\n",
    "    dns = Dense(n)(dp)\n",
    "    bn = BatchNormalization(axis=-1)(dns)\n",
    "    act = Activation(activation=activation)(bn)\n",
    "    return act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_layer(feature_batch, feature_map, kernel_size=(3, 3),strides=(1,1), zp_flag=False):\n",
    "    if zp_flag:\n",
    "        zp = ZeroPadding2D((1,1))(feature_batch)\n",
    "    else:\n",
    "        zp = feature_batch\n",
    "    conv = Conv2D(filters=feature_map, kernel_size=kernel_size, strides=strides)(zp)\n",
    "    bn = BatchNormalization(axis=3)(conv)\n",
    "    act = LeakyReLU(1/10)(bn)\n",
    "    return act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    inp_img = Input(shape=(51, 51, 3))\n",
    "\n",
    "    # 51\n",
    "    conv1 = conv_layer(inp_img, 16, zp_flag=False)\n",
    "    conv2 = conv_layer(conv1, 16, zp_flag=False)\n",
    "    mp1 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2))(conv2)\n",
    "    # 23\n",
    "    conv3 = conv_layer(mp1, 32, zp_flag=False)\n",
    "    conv4 = conv_layer(conv3, 32, zp_flag=False)\n",
    "    mp2 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2))(conv4)\n",
    "    # 9\n",
    "    conv7 = conv_layer(mp2, 64, zp_flag=False)\n",
    "    conv8 = conv_layer(conv7, 64, zp_flag=False)\n",
    "    conv9 = conv_layer(conv8, 64, zp_flag=False)\n",
    "    mp3 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2))(conv9)\n",
    "    # 1\n",
    "    # dense layers\n",
    "    flt = Flatten()(mp3)\n",
    "    ds1 = dense_set(flt, 128, activation='tanh')\n",
    "    out = dense_set(ds1, 12, activation='softmax')\n",
    "\n",
    "    model = Model(inputs=inp_img, outputs=out)\n",
    "    \n",
    "    # The first 50 epochs are used by Adam opt.\n",
    "    # Then 30 epochs are used by SGD opt.\n",
    "    \n",
    "    #mypotim = Adam(lr=2 * 1e-3, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "    mypotim = SGD(lr=1 * 1e-1, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                   optimizer=mypotim,\n",
    "                   metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_callbacks(filepath, patience=5):\n",
    "#     lr_reduce = ReduceLROnPlateau(monitor='val_acc', factor=0.1, epsilon=1e-5, patience=patience, verbose=1)\n",
    "#     msave = ModelCheckpoint(filepath, save_best_only=True)\n",
    "#     return [lr_reduce, msave]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Архитектура MNIST\n",
    "def gen_model():\n",
    "    model = Sequential([\n",
    "        Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(51, 51, 3)),\n",
    "        Conv2D(filters=32, kernel_size=(3, 3), activation='relu'),\n",
    "        Conv2D(filters=32, kernel_size=(3, 3), activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Conv2D(filters=32, kernel_size=(3, 3), activation='relu'),\n",
    "        Conv2D(filters=32, kernel_size=(3, 3), activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Conv2D(filters=32, kernel_size=(3, 3), activation='relu'),\n",
    "        Conv2D(filters=32, kernel_size=(3, 3), activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Dropout(rate=0.25),\n",
    "        Flatten(),\n",
    "        Dense(1024, activation='relu'),\n",
    "        Dense(12, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Методы для обучения и предсказания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(img, target):\n",
    "    callbacks = get_callbacks(filepath='model_weight_SGD.hdf5', patience=6)\n",
    "    gmodel = get_model()\n",
    "#     gmodel.load_weights(filepath='model_weight_Adam.hdf5')\n",
    "    x_train, x_valid, y_train, y_valid = train_test_split(\n",
    "                                                        img,\n",
    "                                                        target,\n",
    "                                                        shuffle=True,\n",
    "                                                        train_size=0.8,\n",
    "                                                        random_state=RANDOM_STATE\n",
    "                                                        )\n",
    "    gen = ImageDataGenerator(\n",
    "            rotation_range=360.,\n",
    "            width_shift_range=0.3,\n",
    "            height_shift_range=0.3,\n",
    "            zoom_range=0.3,\n",
    "            horizontal_flip=True,\n",
    "            vertical_flip=True\n",
    "    )\n",
    "    gmodel.fit_generator(gen.flow(x_train, y_train,batch_size=BATCH_SIZE),\n",
    "               steps_per_epoch=len(x_train)/BATCH_SIZE,\n",
    "               epochs=EPOCHS,\n",
    "               verbose=1,\n",
    "               shuffle=True,\n",
    "               validation_data=(x_valid, y_valid),\n",
    "               callbacks=callbacks\n",
    "               )\n",
    "#     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(img, label):\n",
    "    gmodel = get_model()\n",
    "#     gmodel.load_weights(filepath='../input/plant-weight/model_weight_SGD.hdf5')\n",
    "    prob = gmodel.predict(img, verbose=1)\n",
    "    pred = prob.argmax(axis=-1)\n",
    "    sub = pd.DataFrame({\"file\": label,\n",
    "                         \"species\": [INV_CLASS[p] for p in pred]})\n",
    "    sub.to_csv(\"sub.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# чтение и предобработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_reshape(img):\n",
    "    img = imresize(img, (51, 51, 3))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_label(path):\n",
    "    return str(str(path.split('\\\\')[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_class(path):\n",
    "    return str(path.split('\\\\')[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_dict(paths, some_dict):\n",
    "    text = ''\n",
    "    if 'train' in paths[0]:\n",
    "        text = 'Start fill train_dict'\n",
    "    elif 'test' in paths[0]:\n",
    "        text = 'Start fill test_dict'\n",
    "\n",
    "    for p in tqdm(paths, ascii=True, ncols=85, desc=text):\n",
    "\n",
    "        img = imageio.imread(p)\n",
    "        img = img_reshape(img)\n",
    "        some_dict['image'].append(img)\n",
    "        some_dict['label'].append(img_label(p))\n",
    "        if 'train' in paths[0]:\n",
    "            some_dict['class'].append(img_class(p))\n",
    "    return some_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reader():\n",
    "    file_ext = []\n",
    "    train_path = []\n",
    "    test_path = []\n",
    "\n",
    "    for root, dirs, files in os.walk('Data-hackaton'):\n",
    "        if dirs != []:\n",
    "            print('Root:\\n'+str(root))\n",
    "            print('Dirs:\\n'+str(dirs))\n",
    "        else:\n",
    "            for f in files:\n",
    "                ext = os.path.splitext(str(f))[1][1:]\n",
    "\n",
    "                if ext not in file_ext:\n",
    "                    file_ext.append(ext)\n",
    "\n",
    "                if 'train' in root:\n",
    "                    path = os.path.join(root, f)\n",
    "                    train_path.append(path)\n",
    "                elif 'test' in root:\n",
    "                    path = os.path.join(root, f)\n",
    "                    test_path.append(path)\n",
    "    train_dict = {\n",
    "        'image': [],\n",
    "        'label': [],\n",
    "        'class': []\n",
    "    }\n",
    "    test_dict = {\n",
    "        'image': [],\n",
    "        'label': []\n",
    "    }\n",
    "\n",
    "    train_dict = fill_dict(train_path, train_dict)\n",
    "    test_dict = fill_dict(test_path, test_dict)\n",
    "    return train_dict, test_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Собственно, чтение данных в словарь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root:\n",
      "Data-hackaton\n",
      "Dirs:\n",
      "['test', 'train']\n",
      "Root:\n",
      "Data-hackaton\\train\n",
      "Dirs:\n",
      "['Black-grass', 'Charlock', 'Cleavers', 'Common Chickweed', 'Common wheat', 'Fat Hen', 'Loose Silky-bent', 'Maize', 'Scentless Mayweed', 'Shepherds Purse', 'Small-flowered Cranesbill', 'Sugar beet']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Start fill train_dict:   0%|                                | 0/4750 [00:00<?, ?it/s]C:\\ProgramData\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "\n",
      "Start fill train_dict:   0%|                        | 3/4750 [00:00<08:59,  8.80it/s]\n",
      "Start fill train_dict:   0%|                        | 6/4750 [00:00<09:57,  7.94it/s]\n",
      "Start fill train_dict:   0%|                        | 8/4750 [00:01<16:01,  4.93it/s]\n",
      "Start fill train_dict:   0%|                       | 10/4750 [00:01<13:38,  5.79it/s]\n",
      "Start fill train_dict:   0%|                       | 11/4750 [00:02<17:07,  4.61it/s]\n",
      "Start fill train_dict:   0%|                       | 12/4750 [00:02<16:23,  4.82it/s]\n",
      "Start fill train_dict:   0%|                       | 13/4750 [00:02<17:11,  4.59it/s]\n",
      "Start fill train_dict:   0%|                       | 15/4750 [00:02<15:26,  5.11it/s]\n",
      "Start fill train_dict:   0%|                       | 16/4750 [00:03<16:14,  4.86it/s]\n",
      "Start fill train_dict:   0%|                       | 18/4750 [00:03<15:21,  5.14it/s]\n",
      "Start fill train_dict:   0%|                       | 19/4750 [00:03<15:03,  5.24it/s]\n",
      "Start fill train_dict:   0%|1                      | 21/4750 [00:03<14:20,  5.50it/s]\n",
      "Start fill train_dict:   0%|1                      | 22/4750 [00:04<15:21,  5.13it/s]\n",
      "Start fill train_dict:   0%|1                      | 23/4750 [00:05<18:18,  4.30it/s]\n",
      "Start fill train_dict:   1%|1                      | 24/4750 [00:05<17:55,  4.39it/s]\n",
      "Start fill train_dict:   1%|1                      | 27/4750 [00:05<16:13,  4.85it/s]\n",
      "Start fill train_dict:   1%|1                      | 29/4750 [00:06<17:01,  4.62it/s]\n",
      "Start fill train_dict:   1%|1                      | 31/4750 [00:06<16:12,  4.85it/s]\n",
      "Start fill train_dict:   1%|1                      | 33/4750 [00:06<15:43,  5.00it/s]\n",
      "Start fill train_dict:   1%|1                      | 35/4750 [00:06<15:08,  5.19it/s]\n",
      "Start fill train_dict:   1%|1                      | 37/4750 [00:06<14:42,  5.34it/s]\n",
      "Start fill train_dict:   1%|1                      | 39/4750 [00:07<14:24,  5.45it/s]\n",
      "Start fill train_dict:   1%|1                      | 41/4750 [00:07<14:26,  5.44it/s]\n",
      "Start fill train_dict:   1%|2                      | 43/4750 [00:07<14:06,  5.56it/s]\n",
      "Start fill train_dict: 100%|#####################| 4750/4750 [04:04<00:00, 19.39it/s]\n",
      "Start fill test_dict: 100%|########################| 794/794 [00:16<00:00, 48.51it/s]\n"
     ]
    }
   ],
   "source": [
    "train_dict, test_dict = reader()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Составление необходимых ndarray, передаваемых в модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(train_dict['image'])\n",
    "y_train = to_categorical(np.array([CLASS[l] for l in train_dict['class']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array(test_dict['image'])\n",
    "label = test_dict['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:999: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "  warnings.warn('`epsilon` argument is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 51, 51, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_58 (Conv2D)           (None, 49, 49, 16)        448       \n",
      "_________________________________________________________________\n",
      "batch_normalization_37 (Batc (None, 49, 49, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_29 (LeakyReLU)   (None, 49, 49, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_59 (Conv2D)           (None, 47, 47, 16)        2320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_38 (Batc (None, 47, 47, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_30 (LeakyReLU)   (None, 47, 47, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 23, 23, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_60 (Conv2D)           (None, 21, 21, 32)        4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_39 (Batc (None, 21, 21, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_31 (LeakyReLU)   (None, 21, 21, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_61 (Conv2D)           (None, 19, 19, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_40 (Batc (None, 19, 19, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_32 (LeakyReLU)   (None, 19, 19, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 9, 9, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_62 (Conv2D)           (None, 7, 7, 64)          18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_41 (Batc (None, 7, 7, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_33 (LeakyReLU)   (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_63 (Conv2D)           (None, 5, 5, 64)          36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_42 (Batc (None, 5, 5, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_34 (LeakyReLU)   (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_64 (Conv2D)           (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_43 (Batc (None, 3, 3, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_35 (LeakyReLU)   (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_44 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 12)                1548      \n",
      "_________________________________________________________________\n",
      "batch_normalization_45 (Batc (None, 12)                48        \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 12)                0         \n",
      "=================================================================\n",
      "Total params: 120,588\n",
      "Trainable params: 119,732\n",
      "Non-trainable params: 856\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206/237 [=========================>....] - ETA: 18:05 - loss: 2.8186 - acc: 0.18 - ETA: 10:27 - loss: 2.9883 - acc: 0.09 - ETA: 7:52 - loss: 3.1163 - acc: 0.0833 - ETA: 6:35 - loss: 2.9724 - acc: 0.093 - ETA: 5:48 - loss: 2.9458 - acc: 0.125 - ETA: 5:16 - loss: 2.9134 - acc: 0.135 - ETA: 4:54 - loss: 2.8365 - acc: 0.133 - ETA: 4:37 - loss: 2.8366 - acc: 0.117 - ETA: 4:23 - loss: 2.8005 - acc: 0.118 - ETA: 4:12 - loss: 2.7638 - acc: 0.118 - ETA: 4:03 - loss: 2.7165 - acc: 0.136 - ETA: 3:55 - loss: 2.7115 - acc: 0.130 - ETA: 3:48 - loss: 2.6770 - acc: 0.149 - ETA: 3:42 - loss: 2.6563 - acc: 0.147 - ETA: 3:37 - loss: 2.6273 - acc: 0.154 - ETA: 3:33 - loss: 2.6267 - acc: 0.156 - ETA: 3:29 - loss: 2.6027 - acc: 0.158 - ETA: 3:25 - loss: 2.5861 - acc: 0.163 - ETA: 3:22 - loss: 2.5720 - acc: 0.164 - ETA: 3:18 - loss: 2.5575 - acc: 0.168 - ETA: 3:15 - loss: 2.5473 - acc: 0.166 - ETA: 3:13 - loss: 2.5397 - acc: 0.159 - ETA: 3:10 - loss: 2.5306 - acc: 0.163 - ETA: 3:08 - loss: 2.5283 - acc: 0.166 - ETA: 3:05 - loss: 2.5169 - acc: 0.167 - ETA: 3:03 - loss: 2.4988 - acc: 0.173 - ETA: 3:01 - loss: 2.4840 - acc: 0.178 - ETA: 3:00 - loss: 2.4710 - acc: 0.183 - ETA: 2:58 - loss: 2.4672 - acc: 0.183 - ETA: 2:56 - loss: 2.4689 - acc: 0.181 - ETA: 2:55 - loss: 2.4551 - acc: 0.183 - ETA: 2:53 - loss: 2.4481 - acc: 0.183 - ETA: 2:51 - loss: 2.4427 - acc: 0.183 - ETA: 2:50 - loss: 2.4345 - acc: 0.180 - ETA: 2:49 - loss: 2.4265 - acc: 0.183 - ETA: 2:47 - loss: 2.4307 - acc: 0.184 - ETA: 2:46 - loss: 2.4263 - acc: 0.184 - ETA: 2:44 - loss: 2.4138 - acc: 0.187 - ETA: 2:43 - loss: 2.4133 - acc: 0.185 - ETA: 2:42 - loss: 2.4177 - acc: 0.181 - ETA: 2:41 - loss: 2.4052 - acc: 0.187 - ETA: 2:39 - loss: 2.4047 - acc: 0.187 - ETA: 2:38 - loss: 2.4046 - acc: 0.187 - ETA: 2:37 - loss: 2.3971 - acc: 0.188 - ETA: 2:36 - loss: 2.3938 - acc: 0.190 - ETA: 2:35 - loss: 2.3873 - acc: 0.191 - ETA: 2:34 - loss: 2.3850 - acc: 0.191 - ETA: 2:32 - loss: 2.3765 - acc: 0.195 - ETA: 2:31 - loss: 2.3742 - acc: 0.195 - ETA: 2:30 - loss: 2.3682 - acc: 0.197 - ETA: 2:29 - loss: 2.3588 - acc: 0.203 - ETA: 2:28 - loss: 2.3516 - acc: 0.207 - ETA: 2:27 - loss: 2.3499 - acc: 0.209 - ETA: 2:26 - loss: 2.3493 - acc: 0.209 - ETA: 2:25 - loss: 2.3468 - acc: 0.209 - ETA: 2:24 - loss: 2.3435 - acc: 0.208 - ETA: 2:23 - loss: 2.3417 - acc: 0.208 - ETA: 2:22 - loss: 2.3319 - acc: 0.216 - ETA: 2:21 - loss: 2.3277 - acc: 0.218 - ETA: 2:20 - loss: 2.3265 - acc: 0.219 - ETA: 2:19 - loss: 2.3248 - acc: 0.221 - ETA: 2:18 - loss: 2.3197 - acc: 0.223 - ETA: 2:17 - loss: 2.3110 - acc: 0.228 - ETA: 2:16 - loss: 2.3107 - acc: 0.227 - ETA: 2:15 - loss: 2.3032 - acc: 0.231 - ETA: 2:14 - loss: 2.2964 - acc: 0.233 - ETA: 2:13 - loss: 2.2970 - acc: 0.234 - ETA: 2:12 - loss: 2.2917 - acc: 0.234 - ETA: 2:11 - loss: 2.2879 - acc: 0.234 - ETA: 2:10 - loss: 2.2810 - acc: 0.236 - ETA: 2:09 - loss: 2.2765 - acc: 0.237 - ETA: 2:09 - loss: 2.2695 - acc: 0.240 - ETA: 2:08 - loss: 2.2784 - acc: 0.237 - ETA: 2:07 - loss: 2.2774 - acc: 0.236 - ETA: 2:06 - loss: 2.2702 - acc: 0.239 - ETA: 2:06 - loss: 2.2668 - acc: 0.240 - ETA: 2:05 - loss: 2.2667 - acc: 0.237 - ETA: 2:04 - loss: 2.2670 - acc: 0.236 - ETA: 2:04 - loss: 2.2599 - acc: 0.238 - ETA: 2:03 - loss: 2.2589 - acc: 0.239 - ETA: 2:02 - loss: 2.2555 - acc: 0.241 - ETA: 2:01 - loss: 2.2533 - acc: 0.243 - ETA: 2:00 - loss: 2.2472 - acc: 0.246 - ETA: 1:59 - loss: 2.2451 - acc: 0.245 - ETA: 1:58 - loss: 2.2471 - acc: 0.244 - ETA: 1:58 - loss: 2.2465 - acc: 0.243 - ETA: 1:57 - loss: 2.2420 - acc: 0.243 - ETA: 1:56 - loss: 2.2415 - acc: 0.243 - ETA: 1:55 - loss: 2.2398 - acc: 0.244 - ETA: 1:54 - loss: 2.2361 - acc: 0.244 - ETA: 1:53 - loss: 2.2378 - acc: 0.244 - ETA: 1:52 - loss: 2.2359 - acc: 0.244 - ETA: 1:51 - loss: 2.2330 - acc: 0.247 - ETA: 1:50 - loss: 2.2306 - acc: 0.248 - ETA: 1:50 - loss: 2.2259 - acc: 0.247 - ETA: 1:49 - loss: 2.2231 - acc: 0.250 - ETA: 1:48 - loss: 2.2206 - acc: 0.250 - ETA: 1:47 - loss: 2.2162 - acc: 0.251 - ETA: 1:46 - loss: 2.2118 - acc: 0.253 - ETA: 1:46 - loss: 2.2084 - acc: 0.253 - ETA: 1:45 - loss: 2.2063 - acc: 0.255 - ETA: 1:44 - loss: 2.2053 - acc: 0.254 - ETA: 1:43 - loss: 2.2008 - acc: 0.255 - ETA: 1:42 - loss: 2.1961 - acc: 0.256 - ETA: 1:42 - loss: 2.1932 - acc: 0.257 - ETA: 1:41 - loss: 2.1894 - acc: 0.259 - ETA: 1:40 - loss: 2.1854 - acc: 0.259 - ETA: 1:39 - loss: 2.1824 - acc: 0.260 - ETA: 1:38 - loss: 2.1773 - acc: 0.263 - ETA: 1:37 - loss: 2.1738 - acc: 0.264 - ETA: 1:37 - loss: 2.1711 - acc: 0.266 - ETA: 1:36 - loss: 2.1684 - acc: 0.267 - ETA: 1:35 - loss: 2.1674 - acc: 0.267 - ETA: 1:34 - loss: 2.1670 - acc: 0.268 - ETA: 1:33 - loss: 2.1650 - acc: 0.267 - ETA: 1:33 - loss: 2.1638 - acc: 0.267 - ETA: 1:32 - loss: 2.1680 - acc: 0.266 - ETA: 1:31 - loss: 2.1653 - acc: 0.266 - ETA: 1:30 - loss: 2.1623 - acc: 0.268 - ETA: 1:30 - loss: 2.1650 - acc: 0.267 - ETA: 1:29 - loss: 2.1607 - acc: 0.268 - ETA: 1:28 - loss: 2.1581 - acc: 0.269 - ETA: 1:27 - loss: 2.1550 - acc: 0.269 - ETA: 1:27 - loss: 2.1558 - acc: 0.269 - ETA: 1:26 - loss: 2.1576 - acc: 0.268 - ETA: 1:25 - loss: 2.1562 - acc: 0.267 - ETA: 1:24 - loss: 2.1546 - acc: 0.268 - ETA: 1:24 - loss: 2.1537 - acc: 0.269 - ETA: 1:23 - loss: 2.1508 - acc: 0.270 - ETA: 1:23 - loss: 2.1494 - acc: 0.270 - ETA: 1:22 - loss: 2.1454 - acc: 0.271 - ETA: 1:21 - loss: 2.1425 - acc: 0.272 - ETA: 1:20 - loss: 2.1410 - acc: 0.272 - ETA: 1:19 - loss: 2.1412 - acc: 0.272 - ETA: 1:19 - loss: 2.1406 - acc: 0.271 - ETA: 1:18 - loss: 2.1393 - acc: 0.272 - ETA: 1:17 - loss: 2.1399 - acc: 0.271 - ETA: 1:16 - loss: 2.1355 - acc: 0.273 - ETA: 1:15 - loss: 2.1352 - acc: 0.273 - ETA: 1:15 - loss: 2.1331 - acc: 0.274 - ETA: 1:14 - loss: 2.1310 - acc: 0.273 - ETA: 1:13 - loss: 2.1292 - acc: 0.274 - ETA: 1:12 - loss: 2.1269 - acc: 0.274 - ETA: 1:11 - loss: 2.1238 - acc: 0.275 - ETA: 1:11 - loss: 2.1221 - acc: 0.275 - ETA: 1:10 - loss: 2.1187 - acc: 0.274 - ETA: 1:09 - loss: 2.1159 - acc: 0.276 - ETA: 1:08 - loss: 2.1161 - acc: 0.276 - ETA: 1:07 - loss: 2.1133 - acc: 0.278 - ETA: 1:07 - loss: 2.1124 - acc: 0.278 - ETA: 1:06 - loss: 2.1134 - acc: 0.278 - ETA: 1:05 - loss: 2.1137 - acc: 0.278 - ETA: 1:04 - loss: 2.1094 - acc: 0.279 - ETA: 1:03 - loss: 2.1111 - acc: 0.279 - ETA: 1:03 - loss: 2.1096 - acc: 0.279 - ETA: 1:02 - loss: 2.1097 - acc: 0.279 - ETA: 1:01 - loss: 2.1091 - acc: 0.280 - ETA: 1:00 - loss: 2.1049 - acc: 0.281 - ETA: 1:00 - loss: 2.1033 - acc: 0.281 - ETA: 59s - loss: 2.1042 - acc: 0.281 - ETA: 58s - loss: 2.1021 - acc: 0.28 - ETA: 57s - loss: 2.1019 - acc: 0.28 - ETA: 56s - loss: 2.1004 - acc: 0.28 - ETA: 56s - loss: 2.0982 - acc: 0.28 - ETA: 55s - loss: 2.0971 - acc: 0.28 - ETA: 54s - loss: 2.0935 - acc: 0.28 - ETA: 53s - loss: 2.0910 - acc: 0.28 - ETA: 52s - loss: 2.0901 - acc: 0.28 - ETA: 52s - loss: 2.0884 - acc: 0.28 - ETA: 51s - loss: 2.0884 - acc: 0.28 - ETA: 50s - loss: 2.0848 - acc: 0.28 - ETA: 49s - loss: 2.0851 - acc: 0.28 - ETA: 48s - loss: 2.0803 - acc: 0.29 - ETA: 48s - loss: 2.0809 - acc: 0.29 - ETA: 47s - loss: 2.0790 - acc: 0.29 - ETA: 46s - loss: 2.0804 - acc: 0.29 - ETA: 45s - loss: 2.0784 - acc: 0.29 - ETA: 45s - loss: 2.0774 - acc: 0.29 - ETA: 44s - loss: 2.0770 - acc: 0.29 - ETA: 43s - loss: 2.0735 - acc: 0.29 - ETA: 42s - loss: 2.0729 - acc: 0.29 - ETA: 42s - loss: 2.0715 - acc: 0.29 - ETA: 41s - loss: 2.0689 - acc: 0.29 - ETA: 40s - loss: 2.0687 - acc: 0.29 - ETA: 39s - loss: 2.0659 - acc: 0.29 - ETA: 39s - loss: 2.0658 - acc: 0.29 - ETA: 38s - loss: 2.0637 - acc: 0.29 - ETA: 37s - loss: 2.0626 - acc: 0.29 - ETA: 36s - loss: 2.0627 - acc: 0.29 - ETA: 36s - loss: 2.0624 - acc: 0.29 - ETA: 35s - loss: 2.0605 - acc: 0.29 - ETA: 34s - loss: 2.0570 - acc: 0.29 - ETA: 33s - loss: 2.0557 - acc: 0.29 - ETA: 33s - loss: 2.0537 - acc: 0.29 - ETA: 32s - loss: 2.0536 - acc: 0.29 - ETA: 31s - loss: 2.0535 - acc: 0.29 - ETA: 30s - loss: 2.0534 - acc: 0.29 - ETA: 30s - loss: 2.0545 - acc: 0.29 - ETA: 29s - loss: 2.0547 - acc: 0.29 - ETA: 28s - loss: 2.0540 - acc: 0.29 - ETA: 27s - loss: 2.0518 - acc: 0.29 - ETA: 27s - loss: 2.0501 - acc: 0.29 - ETA: 26s - loss: 2.0478 - acc: 0.29 - ETA: 25s - loss: 2.0477 - acc: 0.29 - ETA: 24s - loss: 2.0462 - acc: 0.30 - ETA: 23s - loss: 2.0448 - acc: 0.3007\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "238/237 [==============================] - ETA: 23s - loss: 2.0430 - acc: 0.30 - ETA: 22s - loss: 2.0412 - acc: 0.30 - ETA: 21s - loss: 2.0386 - acc: 0.30 - ETA: 20s - loss: 2.0384 - acc: 0.30 - ETA: 20s - loss: 2.0351 - acc: 0.30 - ETA: 19s - loss: 2.0324 - acc: 0.30 - ETA: 18s - loss: 2.0299 - acc: 0.30 - ETA: 17s - loss: 2.0292 - acc: 0.30 - ETA: 17s - loss: 2.0254 - acc: 0.30 - ETA: 16s - loss: 2.0260 - acc: 0.30 - ETA: 15s - loss: 2.0237 - acc: 0.30 - ETA: 14s - loss: 2.0229 - acc: 0.30 - ETA: 14s - loss: 2.0249 - acc: 0.30 - ETA: 13s - loss: 2.0224 - acc: 0.30 - ETA: 12s - loss: 2.0222 - acc: 0.30 - ETA: 11s - loss: 2.0216 - acc: 0.30 - ETA: 11s - loss: 2.0209 - acc: 0.30 - ETA: 10s - loss: 2.0190 - acc: 0.30 - ETA: 9s - loss: 2.0175 - acc: 0.3100 - ETA: 8s - loss: 2.0155 - acc: 0.311 - ETA: 7s - loss: 2.0163 - acc: 0.310 - ETA: 7s - loss: 2.0161 - acc: 0.310 - ETA: 6s - loss: 2.0151 - acc: 0.310 - ETA: 5s - loss: 2.0147 - acc: 0.310 - ETA: 4s - loss: 2.0139 - acc: 0.310 - ETA: 4s - loss: 2.0152 - acc: 0.309 - ETA: 3s - loss: 2.0141 - acc: 0.309 - ETA: 2s - loss: 2.0132 - acc: 0.308 - ETA: 1s - loss: 2.0110 - acc: 0.308 - ETA: 1s - loss: 2.0098 - acc: 0.309 - ETA: 0s - loss: 2.0106 - acc: 0.308 - 207s 869ms/step - loss: 2.0094 - acc: 0.3096 - val_loss: 1.6445 - val_acc: 0.4379\n",
      "Epoch 2/30\n",
      " 78/237 [========>.....................] - ETA: 3:35 - loss: 1.7820 - acc: 0.375 - ETA: 3:17 - loss: 1.8391 - acc: 0.312 - ETA: 3:09 - loss: 1.7528 - acc: 0.375 - ETA: 3:02 - loss: 1.7612 - acc: 0.390 - ETA: 3:02 - loss: 1.8471 - acc: 0.387 - ETA: 3:04 - loss: 1.7975 - acc: 0.395 - ETA: 3:05 - loss: 1.7600 - acc: 0.383 - ETA: 3:05 - loss: 1.7478 - acc: 0.406 - ETA: 3:04 - loss: 1.7275 - acc: 0.395 - ETA: 3:02 - loss: 1.7396 - acc: 0.393 - ETA: 3:02 - loss: 1.7255 - acc: 0.397 - ETA: 3:00 - loss: 1.7563 - acc: 0.385 - ETA: 2:58 - loss: 1.7843 - acc: 0.370 - ETA: 2:58 - loss: 1.7731 - acc: 0.375 - ETA: 2:57 - loss: 1.7617 - acc: 0.379 - ETA: 2:55 - loss: 1.7679 - acc: 0.375 - ETA: 2:54 - loss: 1.7829 - acc: 0.364 - ETA: 2:52 - loss: 1.7779 - acc: 0.364 - ETA: 2:51 - loss: 1.7948 - acc: 0.371 - ETA: 2:50 - loss: 1.7896 - acc: 0.371 - ETA: 2:49 - loss: 1.8061 - acc: 0.369 - ETA: 2:48 - loss: 1.7938 - acc: 0.366 - ETA: 2:47 - loss: 1.7976 - acc: 0.364 - ETA: 2:45 - loss: 1.7960 - acc: 0.362 - ETA: 2:44 - loss: 1.8015 - acc: 0.357 - ETA: 2:43 - loss: 1.8328 - acc: 0.351 - ETA: 2:42 - loss: 1.8438 - acc: 0.349 - ETA: 2:41 - loss: 1.8426 - acc: 0.346 - ETA: 2:40 - loss: 1.8381 - acc: 0.344 - ETA: 2:39 - loss: 1.8343 - acc: 0.347 - ETA: 2:38 - loss: 1.8251 - acc: 0.350 - ETA: 2:37 - loss: 1.8279 - acc: 0.345 - ETA: 2:36 - loss: 1.8223 - acc: 0.346 - ETA: 2:35 - loss: 1.8129 - acc: 0.352 - ETA: 2:34 - loss: 1.8078 - acc: 0.350 - ETA: 2:33 - loss: 1.8050 - acc: 0.355 - ETA: 2:32 - loss: 1.7967 - acc: 0.358 - ETA: 2:32 - loss: 1.7940 - acc: 0.358 - ETA: 2:31 - loss: 1.8111 - acc: 0.354 - ETA: 2:31 - loss: 1.8122 - acc: 0.360 - ETA: 2:30 - loss: 1.8029 - acc: 0.367 - ETA: 2:29 - loss: 1.8077 - acc: 0.366 - ETA: 2:28 - loss: 1.8092 - acc: 0.364 - ETA: 2:27 - loss: 1.8141 - acc: 0.365 - ETA: 2:27 - loss: 1.8073 - acc: 0.366 - ETA: 2:26 - loss: 1.8170 - acc: 0.361 - ETA: 2:26 - loss: 1.8076 - acc: 0.363 - ETA: 2:25 - loss: 1.8186 - acc: 0.360 - ETA: 2:24 - loss: 1.8192 - acc: 0.361 - ETA: 2:23 - loss: 1.8204 - acc: 0.360 - ETA: 2:22 - loss: 1.8166 - acc: 0.361 - ETA: 2:22 - loss: 1.8408 - acc: 0.357 - ETA: 2:21 - loss: 1.8395 - acc: 0.353 - ETA: 2:20 - loss: 1.8433 - acc: 0.351 - ETA: 2:19 - loss: 1.8366 - acc: 0.354 - ETA: 2:18 - loss: 1.8316 - acc: 0.354 - ETA: 2:17 - loss: 1.8324 - acc: 0.353 - ETA: 2:17 - loss: 1.8341 - acc: 0.354 - ETA: 2:16 - loss: 1.8292 - acc: 0.359 - ETA: 2:15 - loss: 1.8299 - acc: 0.360 - ETA: 2:15 - loss: 1.8302 - acc: 0.360 - ETA: 2:14 - loss: 1.8249 - acc: 0.361 - ETA: 2:13 - loss: 1.8221 - acc: 0.363 - ETA: 2:12 - loss: 1.8191 - acc: 0.364 - ETA: 2:11 - loss: 1.8171 - acc: 0.364 - ETA: 2:11 - loss: 1.8156 - acc: 0.366 - ETA: 2:10 - loss: 1.8063 - acc: 0.372 - ETA: 2:09 - loss: 1.8058 - acc: 0.374 - ETA: 2:08 - loss: 1.8048 - acc: 0.375 - ETA: 2:07 - loss: 1.8002 - acc: 0.375 - ETA: 2:06 - loss: 1.7976 - acc: 0.375 - ETA: 2:05 - loss: 1.7930 - acc: 0.376 - ETA: 2:05 - loss: 1.7921 - acc: 0.375 - ETA: 2:04 - loss: 1.7912 - acc: 0.377 - ETA: 2:03 - loss: 1.7920 - acc: 0.375 - ETA: 2:02 - loss: 1.7931 - acc: 0.375 - ETA: 2:02 - loss: 1.7888 - acc: 0.376 - ETA: 2:01 - loss: 1.7891 - acc: 0.3774"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-94-e91cfd670cc8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-93-d42050099c69>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(img, target)\u001b[0m\n\u001b[0;32m     24\u001b[0m                \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m                \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m                \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m                )\n\u001b[0;32m     28\u001b[0m \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1424\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1425\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1426\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1427\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1428\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    189\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[0;32m    190\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 191\u001b[1;33m                                             class_weight=class_weight)\n\u001b[0m\u001b[0;32m    192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1218\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1220\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1221\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1222\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2659\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2660\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2661\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2662\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2663\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2629\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2630\u001b[0m                                 session)\n\u001b[1;32m-> 2631\u001b[1;33m         \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2632\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1449\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[1;32m-> 1451\u001b[1;33m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[0;32m   1452\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_model(X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
